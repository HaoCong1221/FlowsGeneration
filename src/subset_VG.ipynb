{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../lib/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import workers\n",
    "import v_ij\n",
    "import math\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load grids, set area and average radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = gpd.read_file('../results/grids_vgr_5km_density_deso.shp')\n",
    "\n",
    "results_output = \"../results/model_output_5km.txt\"\n",
    "results_benchmark = '../results/benchmark_5km.txt'\n",
    "\n",
    "area = 25 # km\n",
    "\n",
    "# A=pi*r_average^2\n",
    "r_average = math.sqrt(area/math.pi) # km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get distance between grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distances between zones...\n"
     ]
    }
   ],
   "source": [
    "# This gives a stacked version\n",
    "distances = workers.zone_distances(grids)\n",
    "# This gives a matrix-style dataframe\n",
    "df_d = distances.unstack(level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get population density and geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = list(grids.zone)\n",
    "population_density = dict(zip(grids.zone, grids.density))\n",
    "geometry = dict(zip(grids.zone, grids.geometry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get $v^{tot}_{ij}$ between grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter = ln(f_max/f_min), f_min = 1/T, f_max = 1 T = 1000\n",
    "T = 1000\n",
    "f_max = 1\n",
    "f_min = 1/T\n",
    "parameter = math.log(f_max / f_min)\n",
    "\n",
    "#ODM = {orig: {desti: v_{ori, desti}}}\n",
    "# orig is the grid_name\n",
    "# desti is the grid_name \n",
    "\n",
    "\n",
    "ODM_tot = dict()\n",
    "for i in range(0, len(grid_name)):\n",
    "    element = dict()\n",
    "    for j in range(i + 1, len(grid_name)):\n",
    "        number_of_trips = v_ij.average_daily_trips(population_density[grid_name[j]], area, r_average, df_d[grid_name[i]][grid_name[j]], parameter) + v_ij.average_daily_trips(population_density[grid_name[i]], area, r_average, df_d[grid_name[i]][grid_name[j]], parameter)\n",
    "        element[grid_name[j]] = number_of_trips\n",
    "    ODM_tot[grid_name[i]] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sweden VG zone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = gpd.read_file('../dbs/sweden/zones/DeSO/DeSO_2018_v2.shp')\n",
    "zones.loc[:, 'deso_3'] = zones.loc[:, 'deso'].apply(lambda x: x[:2])\n",
    "zones_subset = zones.loc[zones['deso_3'] == '14', :]\n",
    "zones_subset_info = dict(zip(zones_subset['deso'], zones_subset['geometry']))\n",
    "zone_name = list(zones_subset['deso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated Deso zone level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\anaconda3\\envs\\geolab\\lib\\site-packages\\geopandas\\geodataframe.py:1351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "zones_subset.loc[:, 'deso_5'] = zones_subset.loc[:, 'deso'].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  $v^{tot}_{ij}$ between aggregated Deso zones in VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover = []\n",
    "checked = set()\n",
    "for i in range(0, len(zone_name)):\n",
    "    sub_cover = []\n",
    "    for j in range(0, len(grid_name)):\n",
    "        if j in checked:\n",
    "            continue\n",
    "        point_j = Point(geometry[grid_name[j]].centroid.x, geometry[grid_name[j]].centroid.y)\n",
    "        if zones_subset_info[zone_name[i]].contains(point_j) == True:\n",
    "            # grid_j in zone_i\n",
    "            sub_cover.append(grid_name[j])\n",
    "            checked.add(j)   # This grid has been occupied, we do not need to check it again.\n",
    "    cover.append(sub_cover)\n",
    "within = dict(zip(zone_name, cover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigzone_name = []\n",
    "bigCover = []\n",
    "subCover = []\n",
    "old_name = zone_name[0][0:5]\n",
    "\n",
    "bigzone_name.append(old_name)\n",
    "subCover.extend(within[zone_name[0]])\n",
    "\n",
    "for i in range(1, len(zone_name)):\n",
    "    new_name = zone_name[i][0:5]\n",
    "\n",
    "    if new_name == old_name:\n",
    "        # this two zones belong the same big zone\n",
    "        subCover.extend(within[zone_name[i]])\n",
    "\n",
    "    if new_name != old_name:\n",
    "        # find a new big zone\n",
    "        #store old results\n",
    "        bigCover.append(deepcopy(subCover))\n",
    "        subCover.clear()\n",
    "\n",
    "        #store new resutls\n",
    "        bigzone_name.append(new_name)\n",
    "        subCover.extend(within[zone_name[i]])\n",
    "\n",
    "    old_name = new_name\n",
    "\n",
    "# handle the lastest case\n",
    "bigCover.append(subCover)\n",
    "\n",
    "\n",
    "big_within = dict(zip(bigzone_name, bigCover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODM_big = dict()\n",
    "for i in range(0, len(bigzone_name)):\n",
    "    element = dict()\n",
    "    for j in range(i, len(bigzone_name)):\n",
    "        if i == j:\n",
    "            average_daily_trips = 0\n",
    "            for begin in range(0, len(big_within[bigzone_name[i]])):\n",
    "                for end in range(begin + 1, len(big_within[bigzone_name[i]])):\n",
    "                    average_daily_trips = average_daily_trips + ODM_tot[big_within[bigzone_name[i]][begin]][big_within[bigzone_name[i]][end]]\n",
    "\n",
    "            element[bigzone_name[j]] = 2 * average_daily_trips\n",
    "        if i != j:\n",
    "            average_daily_trips = 0\n",
    "            for begin in range(0, len(big_within[bigzone_name[i]])):\n",
    "                for end in range(0, len(big_within[bigzone_name[j]])):\n",
    "                    average_daily_trips = average_daily_trips + ODM_tot[big_within[bigzone_name[i]][begin]][big_within[bigzone_name[j]][end]]\n",
    "            element[bigzone_name[j]] = average_daily_trips\n",
    "\n",
    "    ODM_big[bigzone_name[i]] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From upper triangular matrix to a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = np.zeros(len(bigzone_name)*len(bigzone_name))   # the vector of model_output is stored here\n",
    "for i in range(0, len(bigzone_name)):\n",
    "    for j in range(0, len(bigzone_name)):\n",
    "        if i <= j:\n",
    "            model_output[i + j * len(bigzone_name)] = ODM_big[bigzone_name[i]][bigzone_name[j]]\n",
    "        if i > j:\n",
    "            model_output[i + j * len(bigzone_name)] = ODM_big[bigzone_name[j]][bigzone_name[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(results_output, model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#--------------From here we prepare the groundtruth data----------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = gpd.read_file('../dbs/sweden/zones/DeSO/DeSO_2018_v2.shp')\n",
    "zones = zones.rename(columns={\"deso\": \"zone\"})[['zone', 'geometry']]\n",
    "\n",
    "\n",
    "trips = pd.read_csv(\"../dbs/sweden/survey/day_trips.csv\")\n",
    "trips = trips.loc[:, [\"sub_id\", 'trip_id', 'trip_main_id', 'distance_main',\n",
    "                              'date', \"origin_main_deso\", \"desti_main_deso\", 'trip_weight']]\n",
    "trips = trips.drop_duplicates(subset=[\"sub_id\", 'trip_id', 'trip_main_id'])\n",
    "trips[\"T\"] = trips[\"date\"].apply(lambda x: pd.to_datetime(x))\n",
    "trips = trips.loc[~trips[\"T\"].apply(lambda x: x.weekday()).isin([5, 6]), :]\n",
    "trips.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "odms = trips.groupby(['origin_main_deso', 'desti_main_deso']).sum()['trip_weight']\n",
    "odms = odms.reindex(pd.MultiIndex.from_product([zones.zone, zones.zone], names=['ozone', 'dzone']), fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODM = dict()\n",
    "for i in range(0, len(zone_name)):\n",
    "    element = dict()\n",
    "    for j in range(0, len(zone_name)):\n",
    "        element[zone_name[j]] = odms.at[zone_name[i], zone_name[j]]\n",
    "    ODM[zone_name[i]] = element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigzone_name = []\n",
    "bigCover = []\n",
    "subCover = []\n",
    "old_name = zone_name[0][0:5]\n",
    "\n",
    "bigzone_name.append(old_name)\n",
    "subCover.append(zone_name[0])\n",
    "\n",
    "for i in range(1, len(zone_name)):\n",
    "    new_name = zone_name[i][0:5]\n",
    "\n",
    "    if new_name == old_name:\n",
    "        # this two zones belong the same big zone\n",
    "        subCover.append(zone_name[i])\n",
    "\n",
    "    if new_name != old_name:\n",
    "        # find a new big zone\n",
    "        #store old results\n",
    "        bigCover.append(deepcopy(subCover))\n",
    "        subCover.clear()\n",
    "\n",
    "        #store new resutls\n",
    "        bigzone_name.append(new_name)\n",
    "        subCover.append(zone_name[i])\n",
    "\n",
    "    old_name = new_name\n",
    "\n",
    "# handle the lastest case\n",
    "bigCover.append(subCover)\n",
    "\n",
    "\n",
    "big_within = dict(zip(bigzone_name, bigCover))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated groundtruth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODM_truth = dict()\n",
    "for i in range(0, len(bigzone_name)):\n",
    "    element = dict()\n",
    "    for j in range(0, len(bigzone_name)):\n",
    "        average_daily_trips = 0\n",
    "        if i == j:\n",
    "            for begin in range(0, len(big_within[bigzone_name[i]])):\n",
    "                for end in range(0, len(big_within[bigzone_name[i]])):\n",
    "                    average_daily_trips = average_daily_trips + ODM[big_within[bigzone_name[i]][begin]][big_within[bigzone_name[i]][end]]\n",
    "                    \n",
    "        if i != j:\n",
    "            for begin in range(0, len(big_within[bigzone_name[i]])):\n",
    "                for end in range(0, len(big_within[bigzone_name[j]])):\n",
    "                    average_daily_trips = average_daily_trips + ODM[big_within[bigzone_name[i]][begin]][big_within[bigzone_name[j]][end]]\n",
    "        \n",
    "        element[bigzone_name[j]] = average_daily_trips\n",
    "\n",
    "    ODM_truth[bigzone_name[i]] = element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = np.zeros(len(bigzone_name)*len(bigzone_name))   # the vector of groundtruth data is stored here\n",
    "for i in range(0, len(bigzone_name)):\n",
    "    for j in range(0, len(bigzone_name)):\n",
    "            benchmark[i + j * len(bigzone_name)] = ODM_truth[bigzone_name[i]][bigzone_name[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(results_benchmark, benchmark)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f2e54c80dc52ecb462da69c78d850336b81dad0767d9071405d7a4130722d43"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('geolab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
